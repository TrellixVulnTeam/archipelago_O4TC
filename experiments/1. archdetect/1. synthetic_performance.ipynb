{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "from explainer import Archipelago\n",
    "from synthetic_utils import *\n",
    "\n",
    "sys.path.append(\"../../baselines/shapley_interaction_index\")\n",
    "from si_explainer import SiExplainer\n",
    "\n",
    "sys.path.append(\"../../baselines/shapley_taylor_interaction_index\")\n",
    "from sti_explainer import StiExplainer, subset_before\n",
    "\n",
    "sys.path.append(\"../../baselines/mahe_madex/madex\")\n",
    "from utils import general_utils as nid_utils\n",
    "import neural_interaction_detection as nid\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"archdetect\"\n",
    "function_id = 4\n",
    "\n",
    "p = 40 # num features\n",
    "input_value, base_value = 1, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and Synthetic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function id: 4\n"
     ]
    }
   ],
   "source": [
    "input = np.array([input_value]*p)\n",
    "baseline = np.array([base_value]*p)\n",
    "\n",
    "print(\"function id:\", function_id)\n",
    "model = synth_model(function_id, input_value, base_value)\n",
    "gts = model.get_gts(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Baseline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"archdetect\":\n",
    "    apgo = Archipelago(model, input=input, baseline=baseline, output_indices=0, batch_size=20) \n",
    "    inter_scores = apgo.archdetect()[\"interactions\"]\n",
    "    \n",
    "elif method == \"si\":\n",
    "    si_method = SiExplainer(model, input=input, baseline=baseline, output_indices=0, batch_size=20, seed=42)\n",
    "\n",
    "    num_T = 20\n",
    "    inter_scores = []\n",
    "    for i in range(p):\n",
    "        for j in range(i+1, p):\n",
    "            S = (i,j)\n",
    "            att = si_method.attribution(S, num_T)\n",
    "            inter_scores.append( (S, att**2))\n",
    "\n",
    "elif method == \"sti\":\n",
    "    sti_method = StiExplainer(model, input=input, baseline=baseline, output_indices=0, batch_size=20)\n",
    "    \n",
    "    inter_atts = sti_method.batch_attribution(num_orderings=20, pairwise=True, seed=42)\n",
    "    inter_scores = []\n",
    "    for i in range(p):\n",
    "        for j in range(i+1, p):\n",
    "            inter_scores.append( ( (i,j), inter_atts[i,j]**2) )\n",
    "            \n",
    "elif method == \"nid\":\n",
    "    X, Y = gen_data_samples(model, input_value, base_value, p, n=30000, seed=42)\n",
    "    Xs, Ys = nid_utils.proprocess_data(X, Y, valid_size = 10000, test_size=10000, std_scale_X=True, std_scale=True)\n",
    "    inter_scores, mlp_loss = nid.detect_interactions(Xs, Ys, pairwise=True, seed=42)\n",
    "\n",
    "elif method == \"anova\":\n",
    "    X, Y = gen_data_samples(model, input_value, base_value, p, n=30000, seed=42)\n",
    "    Xs, Ys = nid_utils.proprocess_data(X, Y, valid_size = 10000, test_size=10000, std_scale_X=True, std_scale=True)\n",
    "    X_train = Xs[\"train\"]\n",
    "    Y_train = Ys[\"train\"]\n",
    "    \n",
    "    data =  {}\n",
    "    data['y'] = Y_train.squeeze()\n",
    "    st =''\n",
    "    for i in range(0,X_train.shape[1]):    \n",
    "        data['X'+str(i)] = X_train[:,i]\n",
    "        st+='+X'+str(i)\n",
    "    st = \"(\"+st[1:]+\")\"\n",
    "    formula = 'y ~ '+st+\":\"+st\n",
    "\n",
    "    lm = ols(formula,data=data).fit()\n",
    "\n",
    "    table = sm.stats.anova_lm(lm, typ=2)\n",
    "    inter_scores = []\n",
    "    for i, name in enumerate(table.index):\n",
    "        if name == \"Residual\": continue\n",
    "        inter = tuple(int(x) for x in name.replace(\"X\", \"\").split(\":\"))\n",
    "        if len(inter)==1: continue\n",
    "\n",
    "        inter_scores.append((inter, table.values[i,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"auc\", get_auc(inter_scores, gts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
